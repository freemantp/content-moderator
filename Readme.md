## TODO
* use hw (gpu/tpu) support for inference
* use wsgi
* Dockerize
* Specify download location for models
* Use FastAPI
* Write tests
* Count requests
* Authentication

## Start dev server
`uvicorn main:app --reload`